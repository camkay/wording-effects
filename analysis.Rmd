---
title: "Analysis for item wording effects project"
date: "Last updated `r Sys.Date()`"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
---

```{r, include = FALSE}
knitr::opts_chunk$set(warning = F, message = F)
```

# Workspace

```{r}
library(here) # for working with files
library(tidyverse) # for cleaning
library(janitor) # for variable names
library(lme4) # for mulitlevel modeling
library(sjPlot) # for figures
library(ggpubr) # for prettier plots
library(kableExtra) # for nicer tables
```

```{r}
data_path = here("data/Wording_July 12, 2021_18.12.text.csv")

data_labels = read_csv(data_path)

data = read_csv(data_path,
                skip = 3, 
                col_names = names(data_labels))
rm(data_labels)
data = clean_names(data)
```

Remove the following columns.

```{r}
data = data %>%
  select(-end_date,
         -ip_address, 
         -progress, 
         -duration_in_seconds,
         -finished,
         -recorded_date,
         -external_reference, 
         -distribution_channel,
         -user_language,
         -starts_with("recipient"),
         -starts_with("location"),
         -starts_with("meta_info"))
```

# TEMPORARY

```{r}
# rename T_HelpfulD_2

data = rename(data, 
              helpful_d_2 = t_helpful_d_2)
```


# Cleaning

## Recode personality item responses to numeric

We recode the responses to personality items, which we downloaded as text strings. 

```{r}
p_items = str_extract(names(data), "^[[:alpha:]]*_[abcd](_2)?$")
p_items = p_items[!is.na(p_items)]

personality_items = select(data, proid, all_of(p_items))
```

Next we write a simple function to recode values.

```{r}
recode_p = function(x){
  y = case_when(
    x == "Very inaccurate" ~ 1,
    x == "Moderately inaccurate" ~ 2,
    x == "Slightly inaccurate" ~ 3,
    x == "Slightly accurate" ~ 4,
    x == "Moderately accurate" ~ 5,
    x == "Very accurate" ~ 6,
    TRUE ~ NA_real_)
  return(y)
}
```

Finally, we apply this function to all personality items.

```{r}
personality_items = personality_items %>%
  mutate(
    across(!c(proid), recode_p))
```

Now we merge this back into the data.

```{r}
data = select(data, -all_of(p_items))
data = full_join(data, personality_items)
```

## Drop bots

### Based on responses

```{r, echo = F}
olddata = data
```

```{r rm_proid, echo = F}
data = data %>%
  mutate(proid = str_remove(proid, "Value will be set from panel or URL"),
         proid = str_remove(proid, "Value will be set from panel or UR")) %>%
  filter(proid != "")

```


We removed `r nrow(olddata)-nrow(data)` participants without valid Prolific IDs.

```{r, ref.label='rm_proid'}
```

```{r, echo = F}
olddata = data
```

```{r rm_english, echo = F}
data = data %>%
  filter(english %in% c("Well", "Very well (fluent/native)"))
```

We removed `r nrow(olddata)-nrow(data)` participants that do not speak english well or very well.

### Based on patterns

We remove any participant who provides the same response to over half of the items (≥ 17) from a given block in a row.

```{r}
# first, identify unique adjectives, in order
adjectives = p_items %>%
  str_remove_all("_.") %>%
  unique()

# extract block 1 questions
block1 = data %>%
  select(proid, matches("^[[:alpha:]]+_[abcd]$")) 

#rename variables 
n = 0
for(i in adjectives){
  n = n+1
  names(block1) = str_replace(names(block1), i, paste0("trait", str_pad(n, 2, pad = "0")))
}


block1 = block1 %>%
  gather(item, response, -proid) %>%
  filter(!is.na(response)) %>%
  separate(item, into = c("item", "format")) %>%
  select(-format) %>%
  spread(item, response)

block1_runs = numeric(length = nrow(block1))

#   working on this!!!
for(i in 1:nrow(block1)){
  run = 0
  maxrun = 0
  for(j in 3:ncol(block1)){
    if(block1[i,j] == block1[i, j-1]){
      run = run+1
      if(run > maxrun) maxrun = run
      } else{ run = 0}
  } 
  block1_runs[i] = maxrun
}

#add to data frame
block1$block1_runs = block1_runs
```

```{r}
# extract block 2 questions
block2 = data %>%
  select(proid, matches("^[[:alpha:]]+_[abcd]_2$")) 

#rename variables 
n = 0
for(i in adjectives){
  n = n+1
  names(block2) = str_replace(names(block2), i, paste0("trait", str_pad(n, 2, pad = "0")))
}

block2 = block2 %>%
  gather(item, response, -proid) %>%
  filter(!is.na(response)) %>%
  mutate(item = str_remove(item, "_2")) %>%
  separate(item, into = c("item", "format")) %>%
  select(-format) %>%
  spread(item, response)

block2_runs = numeric(length = nrow(block2))

#   working on this!!!
for(i in 1:nrow(block2)){
  run = 0
  maxrun = 0
  for(j in 3:ncol(block2)){
    if(block2[i,j] == block2[i, j-1]){
      run = run+1
      if(run > maxrun) maxrun = run
      } else{ run = 0}
  } 
  block2_runs[i] = maxrun
}

#add to data frame
block2$block2_runs = block2_runs
```

```{r}
#combine results
runs_data = block1 %>%
  select(proid, block1_runs) %>%
  full_join(select(block2, proid, block2_runs)) %>%
  mutate(
    remove = case_when(
      block1_runs >= 17 ~ "Remove",
      block2_runs >= 17 ~ "Remove",
      TRUE ~ "Keep"
    ))
```

```{r, fig.cap = "Maximum number of same consecutive responses in personality blocks."}
#visualize
runs_data %>%
  ggplot(aes(block1_runs, block2_runs)) +
  geom_point(aes(color = remove)) +
  scale_color_manual(values = c("black", "red")) +
  guides(color = "none") +
  labs(
    x = "block 1 runs",
    y = "block 2 runs"
  ) +
  theme_pubr()
```

There were `r table(runs_data$remove)[[2]]` participants who provided the same answer 17 or more times in a row. These participants were removed from the analyses.

```{r}
data = data %>%
  full_join(select(runs_data, proid, remove)) %>%
  filter(remove != "Remove") %>%
  select(-remove)

rm(runs_data)
```

### Based on inattentive responding

We expect to exclude any participant who has an average response of 4 (“slightly agree”) or greater to the attention check items. Two items from the Inattentive and Deviant Responding Inventory for Adjectives (IDRIA) scale (Kay & Saucier, in prep) have been included here, in part to help evaluate the extent of inattentive responding but also to consider the effect of item wording on these items. The two items used here (i.e., “Asleep”, “Human”) were chosen to be as inconspicuous as possible, so as to not to inflate item response durations. The frequency item (i.e., “human”) will be reverse-scored, so that higher scores on both the infrequency and frequency items reflect greater inattentive responding.

```{r}
in_average = data %>%
  # reverse score human
  mutate(across(matches("^human"),  ~(.x*-1)+7)) %>%
  # select id and attention check items
  select(proid, matches("^human"), matches("^asleep")) %>% 
  gather(item, response, -proid) %>%
  filter(!is.na(response)) %>%
  group_by(proid) %>%
  summarise(avg = mean(response)) %>%
  mutate(
    remove = case_when(
      avg >= 4 ~ "Remove",
      TRUE ~ "Keep"))
```
```{r, fig.cap = "Average response to inattention check items"}
in_average %>%
  ggplot(aes(x = avg, fill = remove)) +
  geom_histogram(bins = 20, color = "white") +
  geom_vline(aes(xintercept = 4)) +
  guides(fill = "none") +
  labs(x = "Average response to inattention check items") +
  theme_pubr()
```

We remove `r table(in_average$remove[[2]])` participants whose responses suggest inattention.

```{r}
data = data %>%
  full_join(select(in_average, proid, remove)) %>%
  filter(remove != "Remove") %>%
  select(-remove)
```


## Reverse score personality items

The following items are (typically) negatively correlated with the others: reckless, moody, worrying, nervous, careless, impulsive. We reverse-score them to ease interpretation of associations and means in the later sections. In short, all traits will be scored such that larger numbers are indicative of the more socially desirable end of the specturm.

```{r}
data = data %>%
  mutate(
    across(matches("^reckless"),  ~(.x*-1)+7),
    across(matches("^moody"),     ~(.x*-1)+7),
    across(matches("^worrying"),  ~(.x*-1)+7),
    across(matches("^nervous"),   ~(.x*-1)+7),
    across(matches("^careless"),  ~(.x*-1)+7),
    across(matches("^impulsive"), ~(.x*-1)+7))
  
```



# Analyses

## Format effect

### Data prep

**We will use between-person analyses to compare responses using group-level data for the different formats.**

First we select the responses to the items of different formats. These variable names all have the same format: `[trait]_[abcd]` (for example, `talkative_a`). We search for these items using regular expressions.

```{r}
items_seen_first = str_subset(
  names(data),
  "^([[:alpha:]])+_[abcd]$"
)

item_responses = data %>%
  select(proid, all_of(items_seen_first))
```

Next we reshape these data into long form.

```{r}
item_responses = item_responses %>%
  gather(item, response, -proid) %>%
  separate(item, into = c("item", "format")) %>%
  filter(!is.na(response))
```

### Results

```{r}
item_responses$format = as.factor(item_responses$format)
item_responses$format = relevel(item_responses$format, ref = "a")

mod.format = lmer(response~format + (1|proid), 
                  data = item_responses)
anova(mod.format)
summary(mod.format)

mod.format2 = aov(response~format + Error(proid) , data = item_responses)
summary(mod.format2)

```

```{r}
plot_model(mod.format, type = "pred")
```

```{r}
means_by_group = item_responses %>%
  group_by(format) %>% 
  summarise(m = mean(response),
            s = sd(response))

item_responses %>%
  ggplot(aes(x = response, fill = format)) +
  geom_histogram(bins = 6, color = "white") +
  geom_vline(aes(xintercept = m), data = means_by_group) +
  geom_text(aes(x = 1, 
                y = 125, 
                label = paste("M =", round(m,2), 
                              "\nSD =", round(s,2))), 
            data = means_by_group, 
            hjust =0, 
            vjust = 1) +
  facet_wrap(~format) +
  guides(fill = F) +
  theme_pubr()
```

We can also repeat this analysis separately for each trait. 

```{r, results = 'asis'}
mod_by_item = item_responses %>%
  group_by(item) %>%
  nest() %>%
  mutate(mod = map(data, ~lm(response~format, data = .))) %>%
  mutate(aov = map(mod, anova)) 

mod_by_item %>%
  mutate(tidy = map(aov, broom::tidy)) %>%
  select(item, tidy) %>% 
  unnest(cols = c(tidy)) %>%
  filter(term == "format") %>%
  mutate(p.adj = p.adjust(p.value, method = "holm")) %>%
  mutate(across(
    starts_with("p"),
    papaja::printnum
  )) %>%
  kable(digits = 2, booktabs = T) %>%
  kable_styling()
```

**These analyses will attempt to account for memory effects by collecting data on immediate and delayed recall (5 minutes and approximately two weeks) using a memory paradigm that was developed based on a similar recall task used in the HRS (Runge et al., 2015).**

Within-person analyses will model the proportions of variance attributable to item format, stems of the items (i.e., the content of the adjectives), and the respondent-level variance.

We also plan to evaluate test-retest reliability within formats (within session and over two weeks); we expect slightly higher test-retest reliability for item wording formats that are more specific -- formats #3 and #4 above vs the use of adjectives alone.

We will also consider the effect on retest reliability of performance on the word recall task.

We will further compare response times as a function of item format using both within- and between-person data in order to evaluate the presumption that adjective ratings require less time than phrased items. 

Finally, secondary analyses will consider preliminary evidence for differences (e.g., mean response times, mean level of response) based on the type of device used to complete the survey (mobile, desktop, or tablet).

