---
title: "Power analysis"
date: "Last updated `r Sys.Date()`"
output: 
  bookdown::html_document2:
    toc: TRUE
    toc_float: TRUE
---

```{r power1, echo = F}
run_analyses = TRUE
```


We conduct power analyses for the main research question -- does formatting affect response to personality items -- using a simulation method. That is, we generate datasets of varying sample sizes (from as few as 50 participants per condition to as many as 100), then simulate responses based on the models fit to the pilot data. 

We note here that simulation code does not allow for new data when using models fit using the `glmmmTB` package. Thus, we refit our model in `lme4`, which does allow for new levels.

```{r power2, echo = F}
library(here) # for working with files
library(tidyverse) # for cleaning
library(lme4) # for mulitlevel modeling
library(glmm)
library(broom)
library(ggpubr) # for prettier plots
```

```{r power3, echo = FALSE}
load(here("objects/block1_coded.Rds"))
```


Here we set the sample sizes we'll test, as well as the number of simulations we'll run for each sample size.

```{r power4}
sample_sizes = seq(5, 200, by = 10)

n_sims = 300
```


## Expected response

To simplify our code, we write a function that simulates responses to the model for expected response based on a given sample size, N, and number of repetitions.

Simulate functions for `glmmTMB` do not allow for new data points. However, the coefficient estimate from `lme4 ` match those of the `glmmTMB` output (although calculation of _F_-statistics differs). We use the `lme4` package to simulate new responses but test the model using the `glmmTMB` as we do in the analyses.

```{r power5}
mod.expected_l4 = lmer(response~format + (1|proid), 
                  data = item_block1)
```


```{r power6}
# function to simulate mod.expected_l4

sim_format_b1 = function(n, sims){
  p_vals = numeric(length = sims)
  
  sim_a = expand_grid(
    proid = as.character(1:n),
    item = c(1:33),
    format = "Adjective\nOnly"
  )

  sim_b = expand_grid(
    proid = as.character((n+1):(2*n)),
    item = c(1:33),
    format = "Am\nAdjective"
  )
  
  sim_c = expand_grid(
    proid = as.character(((2*n)+1):(3*n)),
    item = c(1:33),
    format = "Tend to be\nAdjective"
  )
  sim_d = expand_grid(
    proid = as.character(((3*n)+1):(4*n)),
    item = c(1:33),
    format = "Am someone\nwho tends to be\nAdjective"
  )
  
  sim_data = rbind(sim_a, sim_b) %>% rbind(sim_c) %>% rbind(sim_d)
  for (i in 1:sims){
    sim_data$response = simulate(mod.expected_l4, newdata = sim_data, allow.new.levels = T)[,1]
    sim_mod = glmmTMB(response~format + (1|proid), data = sim_data)
    p_vals[i] = tidy(aov(sim_mod))[1, "p.value"][[1]]
    }
  return(p_vals)
}
```

Next we identify the sample sizes for simulation (from 50 to 500 by 25) and create a data frame to hold the results. Power represents the proportion of simulations for which _p_ is less than .05.

```{r power7}
# simulate at various sample sizes
power_df = data.frame(
  N = sample_sizes,
  power = NA_real_
)
```

Here we (inefficiently) loop through all sample sizes and calculate power. Final results are presented in Figure \@ref(fig:power11).

```{r power8, eval = run_analyses}
time1 = Sys.time()
set.seed(20210729)
for(i in sample_sizes){
  pvalues = sim_format_b1(i, n_sims)
  sig = ifelse(pvalues < .05, 1, 0)
  power_df$power[power_df$N == i] <- sum(sig)/n_sims
}
time2 = Sys.time()
time2-time1

```

```{r power9, echo = F, eval = run_analyses}
save(power_df, file = here("objects/power_format_b1.Rdata"))
```

```{r power10, echo = F}
load(here("objects/power_format_b1.Rdata"))
```

```{r power11, echo = F, fig.cap = "Simulated power by sample size per condition for Block 1 in Time 1"}
power_df %>% 
  ggplot(aes(x = N, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    x = "N per condition",
    y = "Simulated power"
  ) +
  theme_pubclean()
```

```{r power12}
#identify minimum sample size

power_df_min = power_df %>% 
  filter(power > .95)

N_min = min(power_df_min$N)
```

The simulation suggests that power would be over the threshold of .95 with a sample size of `r N_min` participants per condition.


## Extreme responding response

```{r power13}
mod.extreme_l4 = glmer(extreme~format + (1|proid), 
                  data = item_block1,
                  family = "binomial")
```


```{r power14}
# function to simulate mod.extreme_l4

sim_format_b2 = function(n, sims){
  p_vals = numeric(length = sims)
  
  sim_a = expand_grid(
    proid = as.character(1:n),
    item = c(1:33),
    format = "Adjective\nOnly"
  )

  sim_b = expand_grid(
    proid = as.character((n+1):(2*n)),
    item = c(1:33),
    format = "Am\nAdjective"
  )
  
  sim_c = expand_grid(
    proid = as.character(((2*n)+1):(3*n)),
    item = c(1:33),
    format = "Tend to be\nAdjective"
  )
  sim_d = expand_grid(
    proid = as.character(((3*n)+1):(4*n)),
    item = c(1:33),
    format = "Am someone\nwho tends to be\nAdjective"
  )
  
  sim_data = rbind(sim_a, sim_b) %>% rbind(sim_c) %>% rbind(sim_d)
  for (i in 1:sims){
    sim_data$extreme = simulate(mod.extreme_l4, newdata = sim_data, allow.new.levels = T)[,1]
    sim_mod = glmmTMB(extreme~format + (1|proid), data = sim_data, family = "binomial")
    p_vals[i] = tidy(aov(sim_mod))[1, "p.value"][[1]]
    }
  return(p_vals)
}
```

Next we identify the sample sizes for simulation (from 50 to 500 by 25) and create a data frame to hold the results. Power represents the proportion of simulations for which _p_ is less than .05.

```{r power15}
# simulate at various sample sizes
power_df = data.frame(
  N = sample_sizes,
  power = 0
)
```

Here we (inefficiently) loop through all sample sizes and calculate power. Final results are presented in Figure \@ref(fig:power19).

```{r power16, eval = run_analyses}
set.seed(20210729)
for(i in sample_sizes){
  pvalues = sim_format_b2(i, n_sims)
  sig = ifelse(pvalues < .05, 1, 0)
  power_df$power[power_df$N == i] <- sum(sig)/n_sims
}
```

```{r power17, echo = F, eval = run_analyses}
save(power_df, file = here("objects/power_format_b2.Rdata"))
```

```{r power18, echo = F}
load(here("objects/power_format_b2.Rdata"))
```

```{r power19, echo = F, fig.cap = "Simulated power by sample size per condition for extreme responding analyses"}
power_df %>% 
  ggplot(aes(x = N, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    x = "N per condition",
    y = "Simulated power"
  ) +
  theme_pubclean()
```

```{r power20}
#identify minimum sample size

power_df_min = power_df %>% 
  filter(power > .95)

N_min = min(power_df_min$N)
```

The simulation suggests that power would be over the threshold of .95 with a sample size of `r N_min` participants per condition.

## Yay-saying

```{r power21}
mod.yaysaying_l4 = glmer(yaysaying~format + (1|proid), 
                  data = item_block1,
                  family = "binomial")
```


```{r power22}
# function to simulate mod.yaysaying_l4

sim_format_b3 = function(n, sims){
  p_vals = numeric(length = sims)
  
  sim_a = expand_grid(
    proid = as.character(1:n),
    item = c(1:33),
    format = "Adjective\nOnly"
  )

  sim_b = expand_grid(
    proid = as.character((n+1):(2*n)),
    item = c(1:33),
    format = "Am\nAdjective"
  )
  
  sim_c = expand_grid(
    proid = as.character(((2*n)+1):(3*n)),
    item = c(1:33),
    format = "Tend to be\nAdjective"
  )
  sim_d = expand_grid(
    proid = as.character(((3*n)+1):(4*n)),
    item = c(1:33),
    format = "Am someone\nwho tends to be\nAdjective"
  )
  
  sim_data = rbind(sim_a, sim_b) %>% rbind(sim_c) %>% rbind(sim_d)
  for (i in 1:sims){
    sim_data$yaysaying = simulate(mod.yaysaying_l4, newdata = sim_data, 
                                  allow.new.levels = T)[,1]
    sim_mod = glmmTMB(yaysaying~format + (1|proid), data = sim_data, family = "binomial")
    p_vals[i] = tidy(aov(sim_mod))[1, "p.value"][[1]]
    }
  return(p_vals)
}
```

Next we identify the sample sizes for simulation (from 50 to 500 by 25) and create a data frame to hold the results. Power represents the proportion of simulations for which _p_ is less than .05.

```{r power23}
# simulate at various sample sizes
power_df = data.frame(
  N = sample_sizes,
  power = 0
)
```

Here we (inefficiently) loop through all sample sizes and calculate power. Final results are presented in Figure \@ref(fig:power27).

```{r power24, eval = run_analyses}
set.seed(20210729)
for(i in sample_sizes){
  pvalues = sim_format_b3(i, n_sims)
  sig = ifelse(pvalues < .05, 1, 0)
  power_df$power[power_df$N == i] <- sum(sig)/n_sims
}
```

```{r power25, echo = F, eval = run_analyses}
save(power_df, file = here("objects/power_format_b3.Rdata"))
```

```{r power26, echo = F}
load(here("objects/power_format_b3.Rdata"))
```

```{r power27, echo = F, fig.cap = "Simulated power by sample size per condition for yaysaying responding analyses"}
power_df %>% 
  ggplot(aes(x = N, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    x = "N per condition",
    y = "Simulated power"
  ) +
  theme_pubclean()
```

```{r power28}
#identify minimum sample size

power_df_min = power_df %>% 
  filter(power > .95)

N_min = min(power_df_min$N)
```

The simulation suggests that power would be over the threshold of .95 with a sample size of `r N_min` participants per condition.
